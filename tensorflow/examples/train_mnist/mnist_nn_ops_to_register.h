// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER

    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
"BinaryOp< CPUDevice, functor::add<float>>",
"ApplyAdamOp<CPUDevice, float>",
"ArgMaxOp<CPUDevice, float, int64>",
"AssignOpT<CPUDevice, float>",
"BCastGradArgsOp<int32>",
"CpuCastOp",
"ConcatV2Op<CPUDevice, ::tensorflow::int32>",
"ConstantOp",
"Conv2DOp<CPUDevice, float>",
"Conv2DCustomBackpropFilterOp<CPUDevice, float>",
"Conv2DCustomBackpropInputOp<CPUDevice, float>",
"BinaryOp< CPUDevice, functor::equal_to<float>>",
"BinaryOp< CPUDevice, functor::equal_to<int64>>",
"ExpandDimsOp<int32>",
"FillOp<CPUDevice, float, int32>",
"UnaryOp< CPUDevice, functor::floor<float>>",
"BinaryOp< CPUDevice, functor::greater<float>>",
"SummaryHistoOp<float>",
"BinaryOp< CPUDevice, functor::safe_floor_div<int32>>",
"IdentityOp",
"SoftmaxOp<CPUDevice, float>",
"MatMulOp<CPUDevice, float, false >",
"MaxPoolingOp<CPUDevice, float>",
"MaxPoolingGradOp<CPUDevice, float>",
"BinaryOp< CPUDevice, functor::maximum<int32>>",
"ReductionOp<CPUDevice, float, int32, Eigen::internal::MeanReducer<float>>",
"SummaryMergeOp",
"BinaryOp< CPUDevice, functor::mul<float>>",
"UnaryOp< CPUDevice, functor::neg<float>>",
"NoOp",
"PackOp<CPUDevice, ::tensorflow::int32>",
"PlaceholderOp",
"ReductionOp<CPUDevice, ::tensorflow::int32, int32, Eigen::internal::ProdReducer<::tensorflow::int32>>",
"IdentityOp",
"PhiloxRandomOp<CPUDevice, random::UniformDistribution< random::PhiloxRandom, float>>",
"BinaryOp< CPUDevice, functor::div<float>>",
"ReluOp<CPUDevice, float>",
"ReluGradOp<CPUDevice, float>",
"ReshapeOp",
"SummaryScalarOp<float>",
"SelectOp<CPUDevice, float>",
"ShapeOp<int32>",
"ShapeNOp<int32>",
"SliceOp<CPUDevice, ::tensorflow::int32>",
"SoftmaxOp<CPUDevice, float>",
"SoftmaxXentWithLogitsOp<CPUDevice, float>",
"SparseSoftmaxXentWithLogitsOp<CPUDevice, float, int64>",
"BinaryOp< CPUDevice, functor::sub<float>>",
"BinaryOp< CPUDevice, functor::sub<int32>>",
"ReductionOp<CPUDevice, float, int32, Eigen::internal::SumReducer<float>>",
"TileOp<CPUDevice, int32>",
"PhiloxRandomOp< CPUDevice, random::TruncatedNormalDistribution< random::SingleSampleAdapter<random::PhiloxRandom>, float>>",
"VariableOp",
"ZerosLikeOp< CPUDevice, float>",
"RecvOp",
"SendOp",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || isequal(op, "Add")
     || isequal(op, "ApplyAdam")
     || isequal(op, "ArgMax")
     || isequal(op, "Assign")
     || isequal(op, "BroadcastGradientArgs")
     || isequal(op, "Cast")
     || isequal(op, "Const")
     || isequal(op, "Conv2D")
     || isequal(op, "Conv2DBackpropFilter")
     || isequal(op, "Conv2DBackpropInput")
     || isequal(op, "Equal")
     || isequal(op, "ExpandDims")
     || isequal(op, "Fill")
     || isequal(op, "Floor")
     || isequal(op, "FloorDiv")
     || isequal(op, "Greater")
     || isequal(op, "HistogramSummary")
     || isequal(op, "Identity")
     || isequal(op, "LogSoftmax")
     || isequal(op, "MatMul")
     || isequal(op, "MaxPool")
     || isequal(op, "MaxPoolGrad")
     || isequal(op, "Mean")
     || isequal(op, "MergeSummary")
     || isequal(op, "Mul")
     || isequal(op, "Neg")
     || isequal(op, "NoOp")
     || isequal(op, "Pack")
     || isequal(op, "Placeholder")
     || isequal(op, "Prod")
     || isequal(op, "PreventGradient")
     || isequal(op, "RandomUniform")
     || isequal(op, "RealDiv")
     || isequal(op, "Relu")
     || isequal(op, "ReluGrad")
     || isequal(op, "Reshape")
     || isequal(op, "ScalarSummary")
     || isequal(op, "Select")
     || isequal(op, "Shape")
     || isequal(op, "ShapeN")
     || isequal(op, "Slice")
     || isequal(op, "Softmax")
     || isequal(op, "SoftmaxCrossEntropyWithLogits")
     || isequal(op, "SparseSoftmaxCrossEntropyWithLogits")
     || isequal(op, "Sub")
     || isequal(op, "Sum")
     || isequal(op, "Tile")
     || isequal(op, "TruncatedNormal")
     || isequal(op, "VariableV2")
     || isequal(op, "ZerosLike")
     || isequal(op, "_Recv")
     || isequal(op, "_Send")
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)

#define SHOULD_REGISTER_OP_GRADIENT true
#endif
